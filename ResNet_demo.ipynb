{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Demo\n",
    "This notebook shows how to train or test the model. Also included are methods to display model outputs and attention mechanimsms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "# from ocra import *\n",
    "from loaddata import *\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# set hyperparams using param file \n",
    "############################################\n",
    "# param file can be 1) multimnist_params.txt or 2) multimnist_cluttered_params.txt\n",
    "# params_filename = 'multimnist_cluttered_params.txt'\n",
    "# params_filename = 'multisvhn_params.txt'\n",
    "params_filename = 'resnet_svrt_task1_params.txt'\n",
    "args = parse_params(params_filename)\n",
    "\n",
    "# if you have a checkpoint to restore, specify restore file (in the orginal param file or here)\n",
    "# args.restore_file =  'results/multimnist_cluttered/Aug28_4014__step7_1/state_checkpoint.pt'\n",
    "if args.restore_file: \n",
    "    # if you want to pick up from save-point, reload param files\n",
    "    print(\"param file will be reloaded from your save point folder\")\n",
    "    path_savepoint = os.path.dirname(args.restore_file)\n",
    "    params_filename = path_savepoint + '/params.txt'  \n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    \n",
    "    # remove the arguments that cannot be translated into literal\n",
    "    removelist = ['device'] \n",
    "    args = parse_params_wremove(params_filename, removelist) \n",
    "    \n",
    "    # reassign path_savepoint to restorefile\n",
    "    args.restore_file = path_savepoint + '/state_checkpoint.pt'\n",
    "            \n",
    "    \n",
    "# setup output directory where log folder should be created \n",
    "if not os.path.isdir(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "# set device\n",
    "# args.device = torch.device('cuda:{}'.format(args.cuda) if torch.cuda.is_available() and args.cuda is not None else 'cpu')\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "pprint.pprint(args.__dict__, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import math\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "\n",
    "\n",
    "def loss_fn(y_pred, y_true, args, writer=None, step=None):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        y_true -- groundtruth y in n-hot format \n",
    "        y_pred -- model predictions; (normalized) cumulative length of class capsules \n",
    "    \"\"\"\n",
    "    #######   Classification Margin Loss      #######\n",
    "    \n",
    "    if len(y_true.shape) == 3: \n",
    "        y_true_1d = torch.clamp(torch.sum(y_true, dim=1), max=1)\n",
    "    else:\n",
    "        y_true_1d = y_true\n",
    "         \n",
    "#     # classification error: margin error for class capsules -- allows for both GT and prediction to have any number for any class \n",
    "#     m_neg = 0.1 # margin loss allowed for negative case (for absent digits)\n",
    "#     lam_abs = 0.5 # down-weighting loss for absent digits (prevent the initial learning from shrinking the lengths of the class capsules    \n",
    "#     L_present =  torch.clamp(y_true_1d, min=0., max=1.) * torch.clamp((y_true_1d-m_neg) - y_pred, min=0.) ** 2   \n",
    "# #     L_present =  y_true_1d * torch.clamp((y_true_1d-m_neg) - y_pred, min=0.) ** 2   # not clamped version\n",
    "#     L_absent = lam_abs * torch.clamp(1 - y_true_1d, min=0.) * torch.clamp(y_pred-m_neg, min=0.) ** 2\n",
    "#     L_margin = (L_present+L_absent).sum(dim=1).mean()\n",
    "    y_true_1d = y_true_1d.argmax(-1)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    L_margin = loss_fn(y_pred, y_true_1d)\n",
    "    return L_margin \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Train and Test\n",
    "# --------------------\n",
    "\n",
    "def get_topkacc(y_pred: torch.Tensor, y_true:  torch.Tensor, topk=1):\n",
    "    \"\"\"\n",
    "    Get indices of topk model predictions and gather how many of them are correct (in percentage).\n",
    "    e.g., if 1 correct out of top2 prediction --> 0.5\n",
    "    \n",
    "    Input: torch tensor\n",
    "        - y_pred should be a vector of prediction score \n",
    "        - y_true should be in multi-hot encoding format (one or zero; can't deal with duplicates)\n",
    "\n",
    "    Return: \n",
    "        - a vector of accuracy from each image --> [n_images,]\n",
    "        - average acc\n",
    "    \"\"\"\n",
    "    n_images = y_pred.size(0)\n",
    "    topk_indices = y_pred.data.topk(topk, sorted=True)[1] \n",
    "    accs = torch.gather(y_true, dim=1, index=topk_indices).sum(dim=1)/topk\n",
    "    average_acc = accs.cpu().sum().item()/n_images\n",
    "\n",
    "    return average_acc, accs\n",
    "\n",
    "def get_exactmatch(y_pred_hot: torch.Tensor, y_true: torch.Tensor):\n",
    "    \"\"\"\n",
    "    See if y_pred and y_true matches exactly\n",
    "    e.g., if match acc=1, not match acc=0\n",
    "    \n",
    "    Input: torch tensor \n",
    "        - both y_pred and y_true should be in the same format\n",
    "        e.g., if y_true is multi-hot, then y_pred should be made in multi-hot as well\n",
    "    Return: \n",
    "        - a vector of accuracy from each image --> [n_images,]\n",
    "        - average acc\n",
    "    \"\"\"\n",
    "    n_images = y_pred_hot.size(0)\n",
    "    accs = (y_pred_hot == y_true).all(dim=1).float()\n",
    "    average_acc = accs.cpu().sum().item()/n_images\n",
    "    \n",
    "    return average_acc, accs\n",
    "\n",
    "def cal_accs(y_pred_nar, y_true, args):\n",
    "    \"\"\" calculate accuracy\n",
    "    1) when args.cat_dup == True --> use criterion value to indicate duplicate classification\n",
    "    2) when args.cat_dup == False --> just topk based accuracy\n",
    "    exact match: if one of digits incorrect  --> 0\n",
    "    partial match: if one of digits incorrect --> 0.5\n",
    "    \n",
    "    return:\n",
    "        - accuracy = accuracy sum over the whole batch\n",
    "        - accs = a list of correct score for each image \n",
    "    \"\"\"\n",
    "    n_targets = args.num_targets\n",
    "    \n",
    "    \n",
    "    if args.task=='multisvhn':  # when there are two targets with duplicates allowed\n",
    "    \n",
    "        col_11 = torch.zeros((y_true.size(0),5, 1)).to(args.device)\n",
    "        col_11[:,1:5, 0] = torch.flip(torch.squeeze(y_true[:,0,10:args.num_classes]), (1,)) \n",
    "        y_true = torch.cat( (y_true[:,:,0:10], col_11), dim=2)\n",
    "\n",
    "\n",
    "        readout_logits = readout_logits.view(-1, 5,11)\n",
    "        out, pred_digits = torch.max(readout_logits,dim=2)\n",
    "        out, true_digits = torch.max(y_true,dim=2)\n",
    "        \n",
    "        partial_accs = torch.sum(1*(pred_digits == true_digits), dim=1) / float(args.num_targets)        \n",
    "        partial_accuracy = partial_accs.cpu().sum().item() \n",
    "        exact_accs = (partial_accs == 1)\n",
    "        exact_accuracy =  exact_accs.cpu().sum().item() \n",
    "        \n",
    "        y_pred_hot = torch.sum(readout_logits, dim=1)\n",
    "        \n",
    "        #exact_accuracy = torch.sum(1* (torch.sum(1*(pred_digits == true_digits), dim=1) == 5)).type('torch.FloatTensor').cpu()  # \n",
    "        \n",
    "    \n",
    "    elif args.cat_dup == True:  # when there are two targets with duplicates allowed\n",
    "        # get bool indices for an image with duplicates\n",
    "        dup_t = n_targets - 0.2# 1.8 for target=2; criterion value indicating duplicates (two targets are from the same category)\n",
    "        bool_above = (y_pred_nar >= dup_t).any(dim=1)\n",
    "\n",
    "        # when any of predictions are above dup_t, apply the following\n",
    "\n",
    "        y_pred_dup = (y_pred_nar == torch.max(y_pred_nar, dim= 1)[0].reshape(-1,1)) # get y_pred for duplicates; the largest value --> mark as 1, e.g., y_pred  [2.1, 0.2, 0.1] --> [1, 0, 0] \n",
    "        # maxid = y_pred_nar.argmax(dim=1)\n",
    "        # y_pred_dup = torch.zeros(y_pred_nar.shape).scatter(1, maxid.unsqueeze(dim=1), 1.0)\n",
    "        dupaccs = torch.sum(y_true*y_pred_dup, dim=1)/2.0 # compare with y_true and get acc, \n",
    "        # e.g, when y_pred_dup = [1, 0, 0], acc=1 when y_true = [2,0,0] and and acc=0.5 when y_true = [1,1,0]\n",
    "\n",
    "        # when none of predictions are above dup_t, apply the following\n",
    "        y_true_clip = torch.clip(y_true,0,1) # y_true [2,0] --> [1,0]\n",
    "        y_pred_nodup = (y_pred_nar >= y_pred_nar.topk(n_targets)[0][:,n_targets-1:n_targets]) # bool indices of predictions higher/equal than n_target highest value  y_pred = [1.0,0.9,0.1] --> [1, 1, 0]\n",
    "        nodupaccs = torch.sum(y_true_clip*y_pred_nodup, dim=1)/float(n_targets)  # compare with y_true and get acc, \n",
    "        # e.g., when y_pred = [1.0,0.9,0.1], acc=1, when y_true = [1,1,0] and acc=0.5, when y_true = [2,0,0]\n",
    "\n",
    "        # combine match for both no duplicates and yes duplicates\n",
    "\n",
    "        y_pred_hot = n_targets*(bool_above.reshape(-1,1)*y_pred_dup)+ (~bool_above).reshape(-1,1)*y_pred_nodup\n",
    "        partial_accs = bool_above*dupaccs + (~bool_above)*nodupaccs\n",
    "        exact_accs = (partial_accs >= 1)\n",
    "        partial_accuracy = partial_accs.cpu().sum().item() # if gt = 1, 2 and pred = 2, 3 --> 50 % acc\n",
    "        exact_accuracy =  exact_accs.cpu().sum().item()  # if gt = 1, 2 and pred = 2, 3 --> 0 % acc\n",
    "        \n",
    "                    \n",
    "    elif args.cat_dup == False: # when no duplicates\n",
    "        y_pred_hot = (y_pred_nar >= y_pred_nar.topk(n_targets)[0][:,n_targets-1:n_targets]) # bool indices of predictions higher/equal than n_target highest value y_pred = [1.0,0.9,0.1] --> [1, 1, 0]\n",
    "        partial_accs = torch.sum(y_pred_hot*y_true, dim=1)/float(n_targets) \n",
    "        partial_accuracy = partial_accs.cpu().sum().item() \n",
    "        exact_accs = (partial_accs >= 1)\n",
    "        exact_accuracy =  exact_accs.cpu().sum().item() \n",
    "        \n",
    "    return y_pred_hot, partial_accuracy, partial_accs, exact_accuracy, exact_accs  \n",
    "            \n",
    "    #     #####################\n",
    "    #     # alternative version: using groundtruth to know whether duplicates trial or not\n",
    "    #     \"\"\"\n",
    "    #     for multimnist, acc should be the same as the version above, acc was ~94% after 3 epoch\n",
    "    #     for cluttered task, acc was 80% after 3 epoch (higher than acc from the version above; ~72-75%%, and 80% was reached around 10 epoch)\n",
    "    #     \"\"\"\n",
    "    #     # get bool indices for an image with duplicates\n",
    "    #     n_targets = args.num_targets\n",
    "    #     bool_duplicate = (y_true==n_targets).any(dim=1) \n",
    "\n",
    "    #     # when no duplicates in the image, apply topk predictions\n",
    "    #     _, top2accs = get_topkacc(y_pred_nar, y_true, topk=2)\n",
    "\n",
    "    #     # when yes duplicates in the image, apply exact match \n",
    "    #     dup_t = 1.85 \n",
    "    #     y_pred_dup = n_targets*(y_pred_nar >= dup_t) # if prediction > dup_t, we consider it as prediction for duplicates, e.g, prediction [1.9, 1.5, 0.5] -> [2, 0, 0]\n",
    "    #     _, matchaccs = get_exactmatch(y_pred_dup, y_true)\n",
    "\n",
    "    #     # combine topk (for no duplicates) + exactmatch (for yes duplicates) and get total sum\n",
    "    #     combaccs = (~bool_duplicate)*top2accs + (bool_duplicate)*matchaccs\n",
    "    #     accuracy = combaccs.cpu().sum().item()\n",
    "    #     #######################\n",
    "\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate(model, x, y_true, loss_fn, args, epoch=None):\n",
    "    \"\"\"\n",
    "    Run model prediction on testing dataset and compute loss/acc \n",
    "    \n",
    "    Args\n",
    "        model -- trained model to be evaluated with no_grad()\n",
    "        recon_mask -- A mask that is the normalized sum of all the read operatoin to focus the erorr reconstructio\n",
    "        x -- input\n",
    "        y_true -- input y in n hot format \n",
    "        y_pred -- (normalized) cumulative length of the class capsules \n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    \n",
    "    # load testing dataset on device\n",
    "    x = torch.cat((x,x,x), dim=1).to(args.device)\n",
    "    \n",
    "#     x = x.view(-1, self.C, self.H, self.W)\n",
    "#     x = x.view(x.shape[0], -1).float().to(args.device)\n",
    "    \n",
    "    if args.task == 'mnist_ctrv':\n",
    "        x = 1.0 - x\n",
    "                \n",
    "    y_true = y_true.to(args.device)\n",
    "    yloss_w = torch.ones((len(x),args.num_classes)).to(args.device)\n",
    "    # run model with testing data and get predictions\n",
    "    y_pred  = model(x)\n",
    "        \n",
    "#     # Do not normalize the sum of object caps lengths if multiple items can be from the same category\n",
    "#     if (not args.cat_dup) and (args.task != 'mnist_ctrv') and (torch.min(torch.max(y_pred, dim=1, keepdim=True)[0]) != 0):\n",
    "#         y_pred = y_pred / torch.max(y_pred, dim=1, keepdim=True)[0] #self.num_objectcaps #objectcaps.norm(dim=-1)   \n",
    "        \n",
    "    # compute accuracy sum over whole batch\n",
    "\n",
    "    _, partial_accuracy, _ , exact_accuracy, _ = cal_accs(y_pred, y_true, args)\n",
    "    \n",
    "    # compute loss    \n",
    "    loss = loss_fn(y_pred, y_true, args)        \n",
    "\n",
    "\n",
    "    return loss, exact_accuracy, partial_accuracy, y_pred\n",
    "\n",
    "\n",
    "def test(model, dataloader, args):\n",
    "    \"\"\"\n",
    "    for each batch:\n",
    "        - evaluate loss & acc ('evaluate')\n",
    "    log average loss & acc  \n",
    "    \"\"\"   \n",
    "    test_loss = 0\n",
    "    test_L_recon = 0\n",
    "    test_L_margin = 0\n",
    "    test_acc_partial = 0\n",
    "    test_acc_exact = 0\n",
    "    \n",
    "    # load batch data\n",
    "    for x, y in dataloader:\n",
    "        \n",
    "        # if one target and y is not in one-hot format, convert it to one-hot encoding\n",
    "#         if args.num_targets == 1:\n",
    "#             if len(y.shape) < 2: \n",
    "#                 y = y.type(torch.int64)\n",
    "#                 y = torch.zeros(y.size(0), args.num_classes).scatter_(1, y.view(-1, 1), 1.)  \n",
    "        \n",
    "        # evaluate\n",
    "        batch_loss, batch_acc_exact, batch_acc_partial, y_pred =  evaluate(model, x, y, loss_fn, args)\n",
    "\n",
    "        # aggregate loss and acc\n",
    "        test_loss += args.test_batch_size * batch_loss\n",
    "        test_acc_partial += batch_acc_partial\n",
    "        test_acc_exact += batch_acc_exact\n",
    "\n",
    "    # get average loss and acc\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    test_acc_partial /= (len(dataloader.dataset))\n",
    "    test_acc_exact /= (len(dataloader.dataset))\n",
    "    return test_loss, test_acc_partial, test_acc_exact\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, train_dataloader, loss_fn, optimizer, epoch, writer, args):\n",
    "    \"\"\"\n",
    "    for each batch:\n",
    "        - forward pass  \n",
    "        - compute loss\n",
    "        - param update\n",
    "    log average train_loss  \n",
    "    \"\"\"    \n",
    "    model.train() \n",
    "    with tqdm(total=len(train_dataloader), desc='epoch {} of {}'.format(epoch, args.n_epochs)) as pbar:\n",
    "#     time.sleep(0.1)        \n",
    "        training_loss = 0.0\n",
    "        \n",
    "        # load batch from dataloader \n",
    "        for i, (x, y, yloss_w) in enumerate(train_dataloader):\n",
    "            global_step = (epoch-1) * len(train_dataloader) + i + 1 #global batch number\n",
    "            \n",
    "            # if one target and y is not in one-hot format, convert it to one-hot encoding\n",
    "#             if args.num_targets == 1:\n",
    "#                 if len(y.shape) < 2: \n",
    "#                     y = y.type(torch.int64)\n",
    "#                     y = torch.zeros(y.size(0), args.num_classes).scatter_(1, y.view(-1, 1), 1.) \n",
    "            \n",
    "            # load dataset on device\n",
    "            x = torch.cat((x,x,x), dim=1).to(args.device)\n",
    "            \n",
    "            if args.task == 'mnist_ctrv':\n",
    "                x = 1.0 - x\n",
    "             \n",
    "            y = y.type(torch.long).to(args.device)\n",
    "            yloss_w = yloss_w.to(args.device)\n",
    "            # forward pass\n",
    "            y_pred = model(x)\n",
    "    \n",
    "            # compute loss for this batch and append it to training loss\n",
    "            loss = loss_fn(y_pred, y, args, writer, global_step)\n",
    "            \n",
    "            training_loss += loss.data #* x.size(0) \n",
    "            \n",
    "            # zero out previous gradients and backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # record grad norm and clip to prevent exploding gradients\n",
    "            if args.record_gradnorm:\n",
    "                grad_norm = 0\n",
    "                for name, p in model.named_parameters():\n",
    "                    grad_norm += p.grad.norm().item() if p.grad is not None else 0\n",
    "                writer.add_scalar('grad_norm', grad_norm, global_step)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "            # update param\n",
    "            optimizer.step()\n",
    "\n",
    "            # end of each batch, update tqdm tracking\n",
    "            pbar.set_postfix(batch_loss='{:.3f}'.format(loss.item()))\n",
    "            pbar.update()\n",
    "    \n",
    "    # logging training info to tensorboard writer\n",
    "    train_loss = training_loss / len(train_dataloader.dataset)\n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    \n",
    "    return train_loss\n",
    "    \n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, loss_fn, optimizer, writer, args):\n",
    "    \"\"\"\n",
    "    for each epoch:\n",
    "        - train the model, update param, and log the training loss ('train_epoch')\n",
    "        - save checkpoint\n",
    "        - compute and log average val loss/acc and\n",
    "        - save best model\n",
    "        \n",
    "    \"\"\"\n",
    "    start_epoch = 1\n",
    "\n",
    "    if args.restore_file:\n",
    "        print('Restoring parameters from {}'.format(args.restore_file))\n",
    "        start_epoch = load_checkpoint(args.restore_file, [model], [optimizer], map_location=args.device.type)\n",
    "        args.n_epochs += start_epoch\n",
    "        print('Resuming training from epoch {}'.format(start_epoch))\n",
    "\n",
    "    for epoch in range(start_epoch, args.n_epochs+1):\n",
    "        \n",
    "        # train epoch\n",
    "        train_loss = train_epoch(model, train_dataloader, loss_fn, optimizer, epoch, writer, args)\n",
    "\n",
    "        # save checkpoint \n",
    "        if args.save_checkpoint:\n",
    "            save_checkpoint({'epoch': epoch,\n",
    "                             'model_state_dicts': [model.state_dict()],\n",
    "                             'optimizer_state_dicts': [optimizer.state_dict()]}, \n",
    "                            checkpoint=args.log_dir,\n",
    "                            quiet=True)\n",
    "        \n",
    "        # compute validation loss and acc\n",
    "        if (epoch) % args.validate_after_howmany_epochs == 0:\n",
    "            val_loss, val_acc_partial, val_acc_exact = test(model, val_dataloader, args)\n",
    "            \n",
    "            # logging validation info to tensorboard writer\n",
    "            writer.add_scalar('Val/Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val/Accuracy_partial', val_acc_partial, epoch)\n",
    "            writer.add_scalar('Val/Accuracy_exact', val_acc_exact, epoch)\n",
    "                        \n",
    "            if args.verbose:\n",
    "                print(\"==> Epoch %02d: train_loss=%.5f, val_loss=%.5f, val_acc_partial=%.4f,  val_acc_exact=%.4f\" \\\n",
    "                  % (epoch, train_loss, val_loss, val_acc_partial, val_acc_exact))\n",
    "               \n",
    "            # update best validation acc and save best model to output dir\n",
    "            if (val_acc_exact > args.best_val_acc):  \n",
    "                args.best_val_acc = val_acc_exact\n",
    "                torch.save(model.state_dict(), args.log_dir +'/best_model_epoch%d_acc%.4f.pt'% (epoch, val_acc_exact))  #output_dir\n",
    "                print(\"the model with best val_acc (%.4f) was saved to disk\" % val_acc_exact)\n",
    "\n",
    "        # for experiments, abort the local mimima trials\n",
    "        if (epoch) % 100 == 0:\n",
    "            if hasattr(args, 'abort_if_valacc_below'):\n",
    "                if (args.best_val_acc < args.abort_if_valacc_below) or math.isnan(val_acc_exact):\n",
    "                    status = f'===== EXPERIMENT ABORTED: val_acc_exact is {val_acc_exact} at epoch {epoch} (Criterion is {args.abort_if_valacc_below}) ===='\n",
    "                    writer.add_text('Status', status, epoch)\n",
    "                    print(status)\n",
    "                    sys.exit()\n",
    "                else:\n",
    "                    status = '==== EXPERIMENT CONTINUE ===='\n",
    "                    writer.add_text('Status', status, epoch)\n",
    "                    print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "# instantiate model \n",
    "############################################\n",
    "import torchvision\n",
    "from torchvision.models import resnet50 \n",
    "\n",
    "\n",
    "class ResNet_model(nn.Module):\n",
    "    \"\"\"Model modified.\n",
    "    The architecture of our model is the same as standard DenseNet121\n",
    "    except the classifier layer which has an additional sigmoid function.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        super(ResNet_model, self).__init__()\n",
    "        \n",
    "        self.num_classes = args.num_classes\n",
    "        \n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "#         model.layer2[0].conv1.stride = (1,1)\n",
    "#         model.layer2[0].downsample[0].stride = (1,1)\n",
    "\n",
    "#         model.layer3[0].conv2.stride = (1,1)\n",
    "#         model.layer3[0].downsample[0].stride = (1,1)\n",
    "\n",
    "#         model.layer4[0].conv1.stride = (1,1)\n",
    "#         model.layer4[0].downsample[0].stride = (1,1)\n",
    "\n",
    "        self.backbone = model \n",
    "        \n",
    "        self.class_readout = nn.Linear(1000, self.num_classes)\n",
    "        \n",
    "#         features = nn.Sequential(*(list(densenet121.children())[0]))\n",
    "#         self.backbone = nn.Sequential(*(list(features.children())[0:11]))\n",
    "        \n",
    "         #Fix the parameters of the feature extractor:\n",
    "#         for param in self.backbone.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "#         self.densenet121.features.denseblock4.denselayer16.conv2.output\n",
    "        \n",
    "#         num_ftrs = self.densenet121.classifier.in_features\n",
    "#         self.densenet121.classifier = nn.Sequential(\n",
    "#             nn.Linear(num_ftrs, out_size),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        y_pred = self.class_readout(x)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "# ---------------------------------------------------------------    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#model = ResNet_model(args).to(args.device) \n",
    "model = ResNet_model(args).to(args.device) \n",
    "\n",
    "# set up model, optimizer, and hooks for monitoring\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "# if args.record_attn_hooks:\n",
    "#     record_forward_backward_attn_hooks(model)\n",
    "\n",
    "# print model info\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# model training...\n",
    "##########################\n",
    "\n",
    "DO_TRAIN = True  # false if you want to skip this cell\n",
    "COMMENT = 'test'\n",
    "\n",
    "if DO_TRAIN:\n",
    "    # load dataloader \n",
    "    train_dataloader, val_dataloader = fetch_dataloader(args, args.train_batch_size, train=True, train_val_split='train-val')\n",
    "\n",
    "    # set writer for tensorboard\n",
    "    writer, current_log_path = set_writer(log_path = args.output_dir if args.restore_file is None else os.path.dirname(args.restore_file),\n",
    "                        comment = COMMENT, \n",
    "                        restore = args.restore_file is not None) \n",
    "\n",
    "    args.log_dir = current_log_path\n",
    "\n",
    "    # save used param info to writer and logging directory\n",
    "    writer.add_text('Params', pprint.pformat(args.__dict__))\n",
    "    \n",
    "    with open(os.path.join(args.log_dir, 'params.txt'), 'w') as f:\n",
    "        pprint.pprint(args.__dict__, f, sort_dicts=False)\n",
    "\n",
    "    # start training\n",
    "    print('Start training with args set above...')\n",
    "    train_and_evaluate(model, train_dataloader, val_dataloader, loss_fn, optimizer, writer, args)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "# from ocra import *\n",
    "from loaddata import *\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# model testing...\n",
    "##########################\n",
    "\n",
    "# testing parameters\n",
    "DO_TEST = True # false if you want to skip this cell\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# give path for the model to load, or None if you want to continue with the current trained model\n",
    "# load_model_path = \"./pretrained/multimnist_cluttered/run1.pt\"\n",
    "load_model_path = None\n",
    "# load_model_path = './results/svrt_task1/Nov27_5848_test/best_model_epoch70_acc0.9899.pt'\n",
    "if DO_TEST:\n",
    "    if load_model_path: \n",
    "        # if path is given, load a saved model (make sure that you loaded right model args)\n",
    "        print(\"param file will be loaded from your saved model folder\")\n",
    "        params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "        assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "\n",
    "        # remove the arguments that caanot be translated into literal\n",
    "        removelist = ['device'] \n",
    "        args = parse_params_wremove(params_filename, removelist) \n",
    "        args.device = device \n",
    "        \n",
    "        # print params\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "        \n",
    "        # load model\n",
    "        model = ResNet_model(args).to(args.device) \n",
    "        model.load_state_dict(torch.load(load_model_path,map_location=args.device))\n",
    "        print('model loaded.')\n",
    "        \n",
    "        # get test results\n",
    "        model.eval()\n",
    "        test_dataloader = fetch_dataloader(args, args.test_batch_size, train=False)\n",
    "        test_loss, test_acc_partial, test_acc_exact = test(model, test_dataloader, args)\n",
    "        print(\"==> Epoch %02d: test_loss=%.5f, test_acc_partial=%.4f, test_acc_exact=%.4f\"\n",
    "              % (args.n_epochs, test_loss, test_acc_partial, test_acc_exact))\n",
    "\n",
    "    else: # use the current trained model to get results\n",
    "        model.eval()\n",
    "        test_dataloader = fetch_dataloader(args, args.test_batch_size, train=False)\n",
    "        test_loss, test_acc_partial, test_acc_exact = test(model, test_dataloader, args)\n",
    "        print(\"==> Epoch %02d: test_loss=%.5f, test_acc_partial=%.4f, test_acc_exact=%.4f\"\n",
    "              % (args.n_epochs, test_loss, test_acc_partial, test_acc_exact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
