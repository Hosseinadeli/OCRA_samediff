{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Demo\n",
    "This notebook shows how to train or test the model. Also included are methods to display model outputs and attention mechanimsms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "# from ocra import *\n",
    "from loaddata import *\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'svrt_task1',\n",
      " 'num_classes': 2,\n",
      " 'num_targets': 1,\n",
      " 'image_dims': (1, 64, 64),\n",
      " 'cat_dup': False,\n",
      " 'n_epochs': 50,\n",
      " 'lr': 0.001,\n",
      " 'train_batch_size': 128,\n",
      " 'test_batch_size': 128,\n",
      " 'cuda': 0,\n",
      " 'data_dir': './data/',\n",
      " 'output_dir': './results/svrt_task1/',\n",
      " 'restore_file': None,\n",
      " 'save_checkpoint': True,\n",
      " 'record_gradnorm': False,\n",
      " 'record_attn_hooks': False,\n",
      " 'validate_after_howmany_epochs': 1,\n",
      " 'best_val_acc': 0,\n",
      " 'verbose': True,\n",
      " 'device': device(type='cuda', index=0)}\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# set hyperparams using param file \n",
    "############################################\n",
    "# param file can be 1) multimnist_params.txt or 2) multimnist_cluttered_params.txt\n",
    "# params_filename = 'multimnist_cluttered_params.txt'\n",
    "# params_filename = 'multisvhn_params.txt'\n",
    "params_filename = 'resnet_svrt_task1_params.txt'\n",
    "args = parse_params(params_filename)\n",
    "\n",
    "# if you have a checkpoint to restore, specify restore file (in the orginal param file or here)\n",
    "# args.restore_file =  'results/multimnist_cluttered/Aug28_4014__step7_1/state_checkpoint.pt'\n",
    "if args.restore_file: \n",
    "    # if you want to pick up from save-point, reload param files\n",
    "    print(\"param file will be reloaded from your save point folder\")\n",
    "    path_savepoint = os.path.dirname(args.restore_file)\n",
    "    params_filename = path_savepoint + '/params.txt'  \n",
    "    assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "    \n",
    "    # remove the arguments that cannot be translated into literal\n",
    "    removelist = ['device'] \n",
    "    args = parse_params_wremove(params_filename, removelist) \n",
    "    \n",
    "    # reassign path_savepoint to restorefile\n",
    "    args.restore_file = path_savepoint + '/state_checkpoint.pt'\n",
    "            \n",
    "    \n",
    "# setup output directory where log folder should be created \n",
    "if not os.path.isdir(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "# set device\n",
    "# args.device = torch.device('cuda:{}'.format(args.cuda) if torch.cuda.is_available() and args.cuda is not None else 'cpu')\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "pprint.pprint(args.__dict__, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import math\n",
    "\n",
    "from utils import *\n",
    "from loaddata import *\n",
    "\n",
    "\n",
    "def loss_fn(y_pred, y_true, args, writer=None, step=None):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        y_true -- groundtruth y in n-hot format \n",
    "        y_pred -- model predictions; (normalized) cumulative length of class capsules \n",
    "    \"\"\"\n",
    "    #######   Classification Margin Loss      #######\n",
    "    \n",
    "    if len(y_true.shape) == 3: \n",
    "        y_true_1d = torch.clamp(torch.sum(y_true, dim=1), max=1)\n",
    "    else:\n",
    "        y_true_1d = y_true\n",
    "         \n",
    "#     # classification error: margin error for class capsules -- allows for both GT and prediction to have any number for any class \n",
    "#     m_neg = 0.1 # margin loss allowed for negative case (for absent digits)\n",
    "#     lam_abs = 0.5 # down-weighting loss for absent digits (prevent the initial learning from shrinking the lengths of the class capsules    \n",
    "#     L_present =  torch.clamp(y_true_1d, min=0., max=1.) * torch.clamp((y_true_1d-m_neg) - y_pred, min=0.) ** 2   \n",
    "# #     L_present =  y_true_1d * torch.clamp((y_true_1d-m_neg) - y_pred, min=0.) ** 2   # not clamped version\n",
    "#     L_absent = lam_abs * torch.clamp(1 - y_true_1d, min=0.) * torch.clamp(y_pred-m_neg, min=0.) ** 2\n",
    "#     L_margin = (L_present+L_absent).sum(dim=1).mean()\n",
    "    y_true_1d = y_true_1d.argmax(-1)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    L_margin = loss_fn(y_pred, y_true_1d)\n",
    "    return L_margin \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Train and Test\n",
    "# --------------------\n",
    "\n",
    "def get_topkacc(y_pred: torch.Tensor, y_true:  torch.Tensor, topk=1):\n",
    "    \"\"\"\n",
    "    Get indices of topk model predictions and gather how many of them are correct (in percentage).\n",
    "    e.g., if 1 correct out of top2 prediction --> 0.5\n",
    "    \n",
    "    Input: torch tensor\n",
    "        - y_pred should be a vector of prediction score \n",
    "        - y_true should be in multi-hot encoding format (one or zero; can't deal with duplicates)\n",
    "\n",
    "    Return: \n",
    "        - a vector of accuracy from each image --> [n_images,]\n",
    "        - average acc\n",
    "    \"\"\"\n",
    "    n_images = y_pred.size(0)\n",
    "    topk_indices = y_pred.data.topk(topk, sorted=True)[1] \n",
    "    accs = torch.gather(y_true, dim=1, index=topk_indices).sum(dim=1)/topk\n",
    "    average_acc = accs.cpu().sum().item()/n_images\n",
    "\n",
    "    return average_acc, accs\n",
    "\n",
    "def get_exactmatch(y_pred_hot: torch.Tensor, y_true: torch.Tensor):\n",
    "    \"\"\"\n",
    "    See if y_pred and y_true matches exactly\n",
    "    e.g., if match acc=1, not match acc=0\n",
    "    \n",
    "    Input: torch tensor \n",
    "        - both y_pred and y_true should be in the same format\n",
    "        e.g., if y_true is multi-hot, then y_pred should be made in multi-hot as well\n",
    "    Return: \n",
    "        - a vector of accuracy from each image --> [n_images,]\n",
    "        - average acc\n",
    "    \"\"\"\n",
    "    n_images = y_pred_hot.size(0)\n",
    "    accs = (y_pred_hot == y_true).all(dim=1).float()\n",
    "    average_acc = accs.cpu().sum().item()/n_images\n",
    "    \n",
    "    return average_acc, accs\n",
    "\n",
    "def cal_accs(y_pred_nar, y_true, args):\n",
    "    \"\"\" calculate accuracy\n",
    "    1) when args.cat_dup == True --> use criterion value to indicate duplicate classification\n",
    "    2) when args.cat_dup == False --> just topk based accuracy\n",
    "    exact match: if one of digits incorrect  --> 0\n",
    "    partial match: if one of digits incorrect --> 0.5\n",
    "    \n",
    "    return:\n",
    "        - accuracy = accuracy sum over the whole batch\n",
    "        - accs = a list of correct score for each image \n",
    "    \"\"\"\n",
    "    n_targets = args.num_targets\n",
    "    \n",
    "    \n",
    "    if args.task=='multisvhn':  # when there are two targets with duplicates allowed\n",
    "    \n",
    "        col_11 = torch.zeros((y_true.size(0),5, 1)).to(args.device)\n",
    "        col_11[:,1:5, 0] = torch.flip(torch.squeeze(y_true[:,0,10:args.num_classes]), (1,)) \n",
    "        y_true = torch.cat( (y_true[:,:,0:10], col_11), dim=2)\n",
    "\n",
    "\n",
    "        readout_logits = readout_logits.view(-1, 5,11)\n",
    "        out, pred_digits = torch.max(readout_logits,dim=2)\n",
    "        out, true_digits = torch.max(y_true,dim=2)\n",
    "        \n",
    "        partial_accs = torch.sum(1*(pred_digits == true_digits), dim=1) / float(args.num_targets)        \n",
    "        partial_accuracy = partial_accs.cpu().sum().item() \n",
    "        exact_accs = (partial_accs == 1)\n",
    "        exact_accuracy =  exact_accs.cpu().sum().item() \n",
    "        \n",
    "        y_pred_hot = torch.sum(readout_logits, dim=1)\n",
    "        \n",
    "        #exact_accuracy = torch.sum(1* (torch.sum(1*(pred_digits == true_digits), dim=1) == 5)).type('torch.FloatTensor').cpu()  # \n",
    "        \n",
    "    \n",
    "    elif args.cat_dup == True:  # when there are two targets with duplicates allowed\n",
    "        # get bool indices for an image with duplicates\n",
    "        dup_t = n_targets - 0.2# 1.8 for target=2; criterion value indicating duplicates (two targets are from the same category)\n",
    "        bool_above = (y_pred_nar >= dup_t).any(dim=1)\n",
    "\n",
    "        # when any of predictions are above dup_t, apply the following\n",
    "\n",
    "        y_pred_dup = (y_pred_nar == torch.max(y_pred_nar, dim= 1)[0].reshape(-1,1)) # get y_pred for duplicates; the largest value --> mark as 1, e.g., y_pred  [2.1, 0.2, 0.1] --> [1, 0, 0] \n",
    "        # maxid = y_pred_nar.argmax(dim=1)\n",
    "        # y_pred_dup = torch.zeros(y_pred_nar.shape).scatter(1, maxid.unsqueeze(dim=1), 1.0)\n",
    "        dupaccs = torch.sum(y_true*y_pred_dup, dim=1)/2.0 # compare with y_true and get acc, \n",
    "        # e.g, when y_pred_dup = [1, 0, 0], acc=1 when y_true = [2,0,0] and and acc=0.5 when y_true = [1,1,0]\n",
    "\n",
    "        # when none of predictions are above dup_t, apply the following\n",
    "        y_true_clip = torch.clip(y_true,0,1) # y_true [2,0] --> [1,0]\n",
    "        y_pred_nodup = (y_pred_nar >= y_pred_nar.topk(n_targets)[0][:,n_targets-1:n_targets]) # bool indices of predictions higher/equal than n_target highest value  y_pred = [1.0,0.9,0.1] --> [1, 1, 0]\n",
    "        nodupaccs = torch.sum(y_true_clip*y_pred_nodup, dim=1)/float(n_targets)  # compare with y_true and get acc, \n",
    "        # e.g., when y_pred = [1.0,0.9,0.1], acc=1, when y_true = [1,1,0] and acc=0.5, when y_true = [2,0,0]\n",
    "\n",
    "        # combine match for both no duplicates and yes duplicates\n",
    "\n",
    "        y_pred_hot = n_targets*(bool_above.reshape(-1,1)*y_pred_dup)+ (~bool_above).reshape(-1,1)*y_pred_nodup\n",
    "        partial_accs = bool_above*dupaccs + (~bool_above)*nodupaccs\n",
    "        exact_accs = (partial_accs >= 1)\n",
    "        partial_accuracy = partial_accs.cpu().sum().item() # if gt = 1, 2 and pred = 2, 3 --> 50 % acc\n",
    "        exact_accuracy =  exact_accs.cpu().sum().item()  # if gt = 1, 2 and pred = 2, 3 --> 0 % acc\n",
    "        \n",
    "                    \n",
    "    elif args.cat_dup == False: # when no duplicates\n",
    "        y_pred_hot = (y_pred_nar >= y_pred_nar.topk(n_targets)[0][:,n_targets-1:n_targets]) # bool indices of predictions higher/equal than n_target highest value y_pred = [1.0,0.9,0.1] --> [1, 1, 0]\n",
    "        partial_accs = torch.sum(y_pred_hot*y_true, dim=1)/float(n_targets) \n",
    "        partial_accuracy = partial_accs.cpu().sum().item() \n",
    "        exact_accs = (partial_accs >= 1)\n",
    "        exact_accuracy =  exact_accs.cpu().sum().item() \n",
    "        \n",
    "    return y_pred_hot, partial_accuracy, partial_accs, exact_accuracy, exact_accs  \n",
    "            \n",
    "    #     #####################\n",
    "    #     # alternative version: using groundtruth to know whether duplicates trial or not\n",
    "    #     \"\"\"\n",
    "    #     for multimnist, acc should be the same as the version above, acc was ~94% after 3 epoch\n",
    "    #     for cluttered task, acc was 80% after 3 epoch (higher than acc from the version above; ~72-75%%, and 80% was reached around 10 epoch)\n",
    "    #     \"\"\"\n",
    "    #     # get bool indices for an image with duplicates\n",
    "    #     n_targets = args.num_targets\n",
    "    #     bool_duplicate = (y_true==n_targets).any(dim=1) \n",
    "\n",
    "    #     # when no duplicates in the image, apply topk predictions\n",
    "    #     _, top2accs = get_topkacc(y_pred_nar, y_true, topk=2)\n",
    "\n",
    "    #     # when yes duplicates in the image, apply exact match \n",
    "    #     dup_t = 1.85 \n",
    "    #     y_pred_dup = n_targets*(y_pred_nar >= dup_t) # if prediction > dup_t, we consider it as prediction for duplicates, e.g, prediction [1.9, 1.5, 0.5] -> [2, 0, 0]\n",
    "    #     _, matchaccs = get_exactmatch(y_pred_dup, y_true)\n",
    "\n",
    "    #     # combine topk (for no duplicates) + exactmatch (for yes duplicates) and get total sum\n",
    "    #     combaccs = (~bool_duplicate)*top2accs + (bool_duplicate)*matchaccs\n",
    "    #     accuracy = combaccs.cpu().sum().item()\n",
    "    #     #######################\n",
    "\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate(model, x, y_true, loss_fn, args, epoch=None):\n",
    "    \"\"\"\n",
    "    Run model prediction on testing dataset and compute loss/acc \n",
    "    \n",
    "    Args\n",
    "        model -- trained model to be evaluated with no_grad()\n",
    "        recon_mask -- A mask that is the normalized sum of all the read operatoin to focus the erorr reconstructio\n",
    "        x -- input\n",
    "        y_true -- input y in n hot format \n",
    "        y_pred -- (normalized) cumulative length of the class capsules \n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    \n",
    "    # load testing dataset on device\n",
    "    x = torch.cat((x,x,x), dim=1).to(args.device)\n",
    "    \n",
    "#     x = x.view(-1, self.C, self.H, self.W)\n",
    "#     x = x.view(x.shape[0], -1).float().to(args.device)\n",
    "    \n",
    "    if args.task == 'mnist_ctrv':\n",
    "        x = 1.0 - x\n",
    "                \n",
    "    y_true = y_true.to(args.device)\n",
    "    yloss_w = torch.ones((len(x),args.num_classes)).to(args.device)\n",
    "    # run model with testing data and get predictions\n",
    "    y_pred  = model(x)\n",
    "        \n",
    "#     # Do not normalize the sum of object caps lengths if multiple items can be from the same category\n",
    "#     if (not args.cat_dup) and (args.task != 'mnist_ctrv') and (torch.min(torch.max(y_pred, dim=1, keepdim=True)[0]) != 0):\n",
    "#         y_pred = y_pred / torch.max(y_pred, dim=1, keepdim=True)[0] #self.num_objectcaps #objectcaps.norm(dim=-1)   \n",
    "        \n",
    "    # compute accuracy sum over whole batch\n",
    "\n",
    "    _, partial_accuracy, _ , exact_accuracy, _ = cal_accs(y_pred, y_true, args)\n",
    "    \n",
    "    # compute loss    \n",
    "    loss = loss_fn(y_pred, y_true, args)        \n",
    "\n",
    "\n",
    "    return loss, exact_accuracy, partial_accuracy, y_pred\n",
    "\n",
    "\n",
    "def test(model, dataloader, args):\n",
    "    \"\"\"\n",
    "    for each batch:\n",
    "        - evaluate loss & acc ('evaluate')\n",
    "    log average loss & acc  \n",
    "    \"\"\"   \n",
    "    test_loss = 0\n",
    "    test_L_recon = 0\n",
    "    test_L_margin = 0\n",
    "    test_acc_partial = 0\n",
    "    test_acc_exact = 0\n",
    "    \n",
    "    # load batch data\n",
    "    for x, y in dataloader:\n",
    "        \n",
    "        # if one target and y is not in one-hot format, convert it to one-hot encoding\n",
    "#         if args.num_targets == 1:\n",
    "#             if len(y.shape) < 2: \n",
    "#                 y = y.type(torch.int64)\n",
    "#                 y = torch.zeros(y.size(0), args.num_classes).scatter_(1, y.view(-1, 1), 1.)  \n",
    "        \n",
    "        # evaluate\n",
    "        batch_loss, batch_acc_exact, batch_acc_partial, y_pred =  evaluate(model, x, y, loss_fn, args)\n",
    "\n",
    "        # aggregate loss and acc\n",
    "        test_loss += args.test_batch_size * batch_loss\n",
    "        test_acc_partial += batch_acc_partial\n",
    "        test_acc_exact += batch_acc_exact\n",
    "\n",
    "    # get average loss and acc\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    test_acc_partial /= (len(dataloader.dataset))\n",
    "    test_acc_exact /= (len(dataloader.dataset))\n",
    "    return test_loss, test_acc_partial, test_acc_exact\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, train_dataloader, loss_fn, optimizer, epoch, writer, args):\n",
    "    \"\"\"\n",
    "    for each batch:\n",
    "        - forward pass  \n",
    "        - compute loss\n",
    "        - param update\n",
    "    log average train_loss  \n",
    "    \"\"\"    \n",
    "    model.train() \n",
    "    with tqdm(total=len(train_dataloader), desc='epoch {} of {}'.format(epoch, args.n_epochs)) as pbar:\n",
    "#     time.sleep(0.1)        \n",
    "        training_loss = 0.0\n",
    "        \n",
    "        # load batch from dataloader \n",
    "        for i, (x, y, yloss_w) in enumerate(train_dataloader):\n",
    "            global_step = (epoch-1) * len(train_dataloader) + i + 1 #global batch number\n",
    "            \n",
    "            # if one target and y is not in one-hot format, convert it to one-hot encoding\n",
    "#             if args.num_targets == 1:\n",
    "#                 if len(y.shape) < 2: \n",
    "#                     y = y.type(torch.int64)\n",
    "#                     y = torch.zeros(y.size(0), args.num_classes).scatter_(1, y.view(-1, 1), 1.) \n",
    "            \n",
    "            # load dataset on device\n",
    "            x = torch.cat((x,x,x), dim=1).to(args.device)\n",
    "            \n",
    "            if args.task == 'mnist_ctrv':\n",
    "                x = 1.0 - x\n",
    "             \n",
    "            y = y.type(torch.long).to(args.device)\n",
    "            yloss_w = yloss_w.to(args.device)\n",
    "            # forward pass\n",
    "            y_pred = model(x)\n",
    "    \n",
    "            # compute loss for this batch and append it to training loss\n",
    "            loss = loss_fn(y_pred, y, args, writer, global_step)\n",
    "            \n",
    "            training_loss += loss.data #* x.size(0) \n",
    "            \n",
    "            # zero out previous gradients and backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # record grad norm and clip to prevent exploding gradients\n",
    "            if args.record_gradnorm:\n",
    "                grad_norm = 0\n",
    "                for name, p in model.named_parameters():\n",
    "                    grad_norm += p.grad.norm().item() if p.grad is not None else 0\n",
    "                writer.add_scalar('grad_norm', grad_norm, global_step)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "            # update param\n",
    "            optimizer.step()\n",
    "\n",
    "            # end of each batch, update tqdm tracking\n",
    "            pbar.set_postfix(batch_loss='{:.3f}'.format(loss.item()))\n",
    "            pbar.update()\n",
    "    \n",
    "    # logging training info to tensorboard writer\n",
    "    train_loss = training_loss / len(train_dataloader.dataset)\n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    \n",
    "    return train_loss\n",
    "    \n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, loss_fn, optimizer, writer, args):\n",
    "    \"\"\"\n",
    "    for each epoch:\n",
    "        - train the model, update param, and log the training loss ('train_epoch')\n",
    "        - save checkpoint\n",
    "        - compute and log average val loss/acc and\n",
    "        - save best model\n",
    "        \n",
    "    \"\"\"\n",
    "    start_epoch = 1\n",
    "\n",
    "    if args.restore_file:\n",
    "        print('Restoring parameters from {}'.format(args.restore_file))\n",
    "        start_epoch = load_checkpoint(args.restore_file, [model], [optimizer], map_location=args.device.type)\n",
    "        args.n_epochs += start_epoch\n",
    "        print('Resuming training from epoch {}'.format(start_epoch))\n",
    "\n",
    "    for epoch in range(start_epoch, args.n_epochs+1):\n",
    "        \n",
    "        # train epoch\n",
    "        train_loss = train_epoch(model, train_dataloader, loss_fn, optimizer, epoch, writer, args)\n",
    "\n",
    "        # save checkpoint \n",
    "        if args.save_checkpoint:\n",
    "            save_checkpoint({'epoch': epoch,\n",
    "                             'model_state_dicts': [model.state_dict()],\n",
    "                             'optimizer_state_dicts': [optimizer.state_dict()]}, \n",
    "                            checkpoint=args.log_dir,\n",
    "                            quiet=True)\n",
    "        \n",
    "        # compute validation loss and acc\n",
    "        if (epoch) % args.validate_after_howmany_epochs == 0:\n",
    "            val_loss, val_acc_partial, val_acc_exact = test(model, val_dataloader, args)\n",
    "            \n",
    "            # logging validation info to tensorboard writer\n",
    "            writer.add_scalar('Val/Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val/Accuracy_partial', val_acc_partial, epoch)\n",
    "            writer.add_scalar('Val/Accuracy_exact', val_acc_exact, epoch)\n",
    "                        \n",
    "            if args.verbose:\n",
    "                print(\"==> Epoch %02d: train_loss=%.5f, val_loss=%.5f, val_acc_partial=%.4f,  val_acc_exact=%.4f\" \\\n",
    "                  % (epoch, train_loss, val_loss, val_acc_partial, val_acc_exact))\n",
    "               \n",
    "            # update best validation acc and save best model to output dir\n",
    "            if (val_acc_exact > args.best_val_acc):  \n",
    "                args.best_val_acc = val_acc_exact\n",
    "                torch.save(model.state_dict(), args.log_dir +'/best_model_epoch%d_acc%.4f.pt'% (epoch, val_acc_exact))  #output_dir\n",
    "                print(\"the model with best val_acc (%.4f) was saved to disk\" % val_acc_exact)\n",
    "\n",
    "        # for experiments, abort the local mimima trials\n",
    "        if (epoch) % 100 == 0:\n",
    "            if hasattr(args, 'abort_if_valacc_below'):\n",
    "                if (args.best_val_acc < args.abort_if_valacc_below) or math.isnan(val_acc_exact):\n",
    "                    status = f'===== EXPERIMENT ABORTED: val_acc_exact is {val_acc_exact} at epoch {epoch} (Criterion is {args.abort_if_valacc_below}) ===='\n",
    "                    writer.add_text('Status', status, epoch)\n",
    "                    print(status)\n",
    "                    sys.exit()\n",
    "                else:\n",
    "                    status = '==== EXPERIMENT CONTINUE ===='\n",
    "                    writer.add_text('Status', status, epoch)\n",
    "                    print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+------------+\n",
      "|                Modules                | Parameters |\n",
      "+---------------------------------------+------------+\n",
      "|         backbone.conv1.weight         |    9408    |\n",
      "|          backbone.bn1.weight          |     64     |\n",
      "|           backbone.bn1.bias           |     64     |\n",
      "|     backbone.layer1.0.conv1.weight    |   36864    |\n",
      "|      backbone.layer1.0.bn1.weight     |     64     |\n",
      "|       backbone.layer1.0.bn1.bias      |     64     |\n",
      "|     backbone.layer1.0.conv2.weight    |   36864    |\n",
      "|      backbone.layer1.0.bn2.weight     |     64     |\n",
      "|       backbone.layer1.0.bn2.bias      |     64     |\n",
      "|     backbone.layer1.1.conv1.weight    |   36864    |\n",
      "|      backbone.layer1.1.bn1.weight     |     64     |\n",
      "|       backbone.layer1.1.bn1.bias      |     64     |\n",
      "|     backbone.layer1.1.conv2.weight    |   36864    |\n",
      "|      backbone.layer1.1.bn2.weight     |     64     |\n",
      "|       backbone.layer1.1.bn2.bias      |     64     |\n",
      "|     backbone.layer2.0.conv1.weight    |   73728    |\n",
      "|      backbone.layer2.0.bn1.weight     |    128     |\n",
      "|       backbone.layer2.0.bn1.bias      |    128     |\n",
      "|     backbone.layer2.0.conv2.weight    |   147456   |\n",
      "|      backbone.layer2.0.bn2.weight     |    128     |\n",
      "|       backbone.layer2.0.bn2.bias      |    128     |\n",
      "| backbone.layer2.0.downsample.0.weight |    8192    |\n",
      "| backbone.layer2.0.downsample.1.weight |    128     |\n",
      "|  backbone.layer2.0.downsample.1.bias  |    128     |\n",
      "|     backbone.layer2.1.conv1.weight    |   147456   |\n",
      "|      backbone.layer2.1.bn1.weight     |    128     |\n",
      "|       backbone.layer2.1.bn1.bias      |    128     |\n",
      "|     backbone.layer2.1.conv2.weight    |   147456   |\n",
      "|      backbone.layer2.1.bn2.weight     |    128     |\n",
      "|       backbone.layer2.1.bn2.bias      |    128     |\n",
      "|     backbone.layer3.0.conv1.weight    |   294912   |\n",
      "|      backbone.layer3.0.bn1.weight     |    256     |\n",
      "|       backbone.layer3.0.bn1.bias      |    256     |\n",
      "|     backbone.layer3.0.conv2.weight    |   589824   |\n",
      "|      backbone.layer3.0.bn2.weight     |    256     |\n",
      "|       backbone.layer3.0.bn2.bias      |    256     |\n",
      "| backbone.layer3.0.downsample.0.weight |   32768    |\n",
      "| backbone.layer3.0.downsample.1.weight |    256     |\n",
      "|  backbone.layer3.0.downsample.1.bias  |    256     |\n",
      "|     backbone.layer3.1.conv1.weight    |   589824   |\n",
      "|      backbone.layer3.1.bn1.weight     |    256     |\n",
      "|       backbone.layer3.1.bn1.bias      |    256     |\n",
      "|     backbone.layer3.1.conv2.weight    |   589824   |\n",
      "|      backbone.layer3.1.bn2.weight     |    256     |\n",
      "|       backbone.layer3.1.bn2.bias      |    256     |\n",
      "|     backbone.layer4.0.conv1.weight    |  1179648   |\n",
      "|      backbone.layer4.0.bn1.weight     |    512     |\n",
      "|       backbone.layer4.0.bn1.bias      |    512     |\n",
      "|     backbone.layer4.0.conv2.weight    |  2359296   |\n",
      "|      backbone.layer4.0.bn2.weight     |    512     |\n",
      "|       backbone.layer4.0.bn2.bias      |    512     |\n",
      "| backbone.layer4.0.downsample.0.weight |   131072   |\n",
      "| backbone.layer4.0.downsample.1.weight |    512     |\n",
      "|  backbone.layer4.0.downsample.1.bias  |    512     |\n",
      "|     backbone.layer4.1.conv1.weight    |  2359296   |\n",
      "|      backbone.layer4.1.bn1.weight     |    512     |\n",
      "|       backbone.layer4.1.bn1.bias      |    512     |\n",
      "|     backbone.layer4.1.conv2.weight    |  2359296   |\n",
      "|      backbone.layer4.1.bn2.weight     |    512     |\n",
      "|       backbone.layer4.1.bn2.bias      |    512     |\n",
      "|           backbone.fc.weight          |   512000   |\n",
      "|            backbone.fc.bias           |    1000    |\n",
      "|          class_readout.weight         |    2000    |\n",
      "|           class_readout.bias          |     2      |\n",
      "+---------------------------------------+------------+\n",
      "Total Trainable Params: 11691514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11691514"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "# instantiate model \n",
    "############################################\n",
    "import torchvision\n",
    "from torchvision.models import resnet50 \n",
    "\n",
    "\n",
    "class ResNet_model(nn.Module):\n",
    "    \"\"\"Model modified.\n",
    "    The architecture of our model is the same as standard DenseNet121\n",
    "    except the classifier layer which has an additional sigmoid function.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        super(ResNet_model, self).__init__()\n",
    "        \n",
    "        self.num_classes = args.num_classes\n",
    "        \n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "#         model.layer2[0].conv1.stride = (1,1)\n",
    "#         model.layer2[0].downsample[0].stride = (1,1)\n",
    "\n",
    "#         model.layer3[0].conv2.stride = (1,1)\n",
    "#         model.layer3[0].downsample[0].stride = (1,1)\n",
    "\n",
    "#         model.layer4[0].conv1.stride = (1,1)\n",
    "#         model.layer4[0].downsample[0].stride = (1,1)\n",
    "\n",
    "        self.backbone = model \n",
    "        \n",
    "        self.class_readout = nn.Linear(1000, self.num_classes)\n",
    "        \n",
    "#         features = nn.Sequential(*(list(densenet121.children())[0]))\n",
    "#         self.backbone = nn.Sequential(*(list(features.children())[0:11]))\n",
    "        \n",
    "         #Fix the parameters of the feature extractor:\n",
    "#         for param in self.backbone.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "#         self.densenet121.features.denseblock4.denselayer16.conv2.output\n",
    "        \n",
    "#         num_ftrs = self.densenet121.classifier.in_features\n",
    "#         self.densenet121.classifier = nn.Sequential(\n",
    "#             nn.Linear(num_ftrs, out_size),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        y_pred = self.class_readout(x)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "# ---------------------------------------------------------------    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#model = ResNet_model(args).to(args.device) \n",
    "model = ResNet_model(args).to(args.device) \n",
    "\n",
    "# set up model, optimizer, and hooks for monitoring\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "# if args.record_attn_hooks:\n",
    "#     record_forward_backward_attn_hooks(model)\n",
    "\n",
    "# print model info\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with args set above...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6b5626f2ac4fc8a528bdec2ed18bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 01: train_loss=0.00462, val_loss=0.31400, val_acc_partial=0.8693,  val_acc_exact=0.8693\n",
      "the model with best val_acc (0.8693) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e5ed4477794dd3a10123ca0e002b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 02: train_loss=0.00156, val_loss=0.14430, val_acc_partial=0.9488,  val_acc_exact=0.9488\n",
      "the model with best val_acc (0.9488) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d49ac07642345a99f4746fd30b2477a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 03: train_loss=0.00082, val_loss=0.11038, val_acc_partial=0.9602,  val_acc_exact=0.9602\n",
      "the model with best val_acc (0.9602) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f6023d0292443caaff0f7ba4f67237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 04: train_loss=0.00215, val_loss=0.70169, val_acc_partial=0.5018,  val_acc_exact=0.5018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efa6fe6a6a04b9a8151023ee27b2b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 05: train_loss=0.00277, val_loss=0.11907, val_acc_partial=0.9591,  val_acc_exact=0.9591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a795b07649d8406aa70c4f3c04537194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 06: train_loss=0.00048, val_loss=0.09095, val_acc_partial=0.9709,  val_acc_exact=0.9709\n",
      "the model with best val_acc (0.9709) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44726a82f51c4b40aa6bb63b8fdfbfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 07: train_loss=0.00028, val_loss=0.08606, val_acc_partial=0.9773,  val_acc_exact=0.9773\n",
      "the model with best val_acc (0.9773) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d6036087db46d998105cf87516e8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 08: train_loss=0.00044, val_loss=0.09459, val_acc_partial=0.9746,  val_acc_exact=0.9746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21ce0c3290e4a72bc610e916259c2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 09: train_loss=0.00019, val_loss=0.07969, val_acc_partial=0.9790,  val_acc_exact=0.9790\n",
      "the model with best val_acc (0.9790) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db02b36926b04969a2e6f263fade864f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 10: train_loss=0.00014, val_loss=0.11362, val_acc_partial=0.9732,  val_acc_exact=0.9732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f9ddcb80a24f658a2ad6cff67f33c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 11 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 11: train_loss=0.00014, val_loss=0.11858, val_acc_partial=0.9734,  val_acc_exact=0.9734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dc57ce3eca4c78b6d9baf547ac9dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 12 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 12: train_loss=0.00014, val_loss=0.08921, val_acc_partial=0.9794,  val_acc_exact=0.9794\n",
      "the model with best val_acc (0.9794) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c26ad0baa84c6db810e456b6c91f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 13 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 13: train_loss=0.00013, val_loss=0.07771, val_acc_partial=0.9797,  val_acc_exact=0.9797\n",
      "the model with best val_acc (0.9797) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7bdf3767164570a08804da21b57571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 14 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 14: train_loss=0.00058, val_loss=0.14953, val_acc_partial=0.9479,  val_acc_exact=0.9479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb85020026b742a19e0b875c1b6b69c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 15 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 15: train_loss=0.00024, val_loss=0.07801, val_acc_partial=0.9797,  val_acc_exact=0.9797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226546716ae24c49b8e75f93ae562d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 16 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 16: train_loss=0.00032, val_loss=0.07350, val_acc_partial=0.9788,  val_acc_exact=0.9788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fefffbfdc804786bc75cde19bb976fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 17 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 17: train_loss=0.00009, val_loss=0.07354, val_acc_partial=0.9832,  val_acc_exact=0.9832\n",
      "the model with best val_acc (0.9832) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4a8186c70c468a893fdd1c87f34d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 18 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 18: train_loss=0.00008, val_loss=0.09073, val_acc_partial=0.9825,  val_acc_exact=0.9825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dfb13832c94cbca2222e670e05b4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 19 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 19: train_loss=0.00008, val_loss=0.06307, val_acc_partial=0.9832,  val_acc_exact=0.9832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0901abe47364d9c9298268081b05733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 20 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 20: train_loss=0.00783, val_loss=0.69956, val_acc_partial=0.5034,  val_acc_exact=0.5034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bd569f48fe45dc87766a8b606f23da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 21 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 21: train_loss=0.00542, val_loss=0.63812, val_acc_partial=0.6473,  val_acc_exact=0.6473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131111ce37e54937adcc0d3fdfccca73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 22 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 22: train_loss=0.00098, val_loss=0.06705, val_acc_partial=0.9805,  val_acc_exact=0.9805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89774ac0a3ce49109b405cfdf710e6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 23 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 23: train_loss=0.00012, val_loss=0.07366, val_acc_partial=0.9831,  val_acc_exact=0.9831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113a69e1773748efb8e76f596e804dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 24 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 24: train_loss=0.00008, val_loss=0.06236, val_acc_partial=0.9825,  val_acc_exact=0.9825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1a0ff2dc3f4a96a9fbb672ac2349c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 25 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 25: train_loss=0.00006, val_loss=0.07051, val_acc_partial=0.9837,  val_acc_exact=0.9837\n",
      "the model with best val_acc (0.9837) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb58cd06afb4098b6ea54463e41300c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 26 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 26: train_loss=0.00007, val_loss=0.06297, val_acc_partial=0.9850,  val_acc_exact=0.9850\n",
      "the model with best val_acc (0.9850) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb050cc060249d59eef63fb87361d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 27 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 27: train_loss=0.00007, val_loss=0.05961, val_acc_partial=0.9855,  val_acc_exact=0.9855\n",
      "the model with best val_acc (0.9855) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc62792e224ef283431426378edb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 28 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 28: train_loss=0.00008, val_loss=0.06525, val_acc_partial=0.9846,  val_acc_exact=0.9846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a571b88405184f9cb3fa9b03066558dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 29 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 29: train_loss=0.00007, val_loss=0.06373, val_acc_partial=0.9842,  val_acc_exact=0.9842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd456c2826ed41e29a274ad2dd48ec1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 30 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 30: train_loss=0.00006, val_loss=0.06917, val_acc_partial=0.9834,  val_acc_exact=0.9834\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb67b9cea664fd9be870a0cfa6cc21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 31 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 31: train_loss=0.00007, val_loss=0.07629, val_acc_partial=0.9814,  val_acc_exact=0.9814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddda458a75064536a0029174fa327d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 32 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 32: train_loss=0.00007, val_loss=0.06491, val_acc_partial=0.9826,  val_acc_exact=0.9826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729b2de2371349eb85b31429815602ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 33 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 33: train_loss=0.00007, val_loss=0.07412, val_acc_partial=0.9842,  val_acc_exact=0.9842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfd75cd7f2249e3afed8665a78ec906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 34 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 34: train_loss=0.00005, val_loss=0.07233, val_acc_partial=0.9846,  val_acc_exact=0.9846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed89ccbde8e496e9f0281a175fdbb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 35 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 35: train_loss=0.00005, val_loss=0.06247, val_acc_partial=0.9848,  val_acc_exact=0.9848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519e4a4d42924a78bbe769cc9e9a51c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 36 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 36: train_loss=0.00005, val_loss=0.06992, val_acc_partial=0.9856,  val_acc_exact=0.9856\n",
      "the model with best val_acc (0.9856) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08f8c5268994b94b76904f8bd4a97f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 37 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 37: train_loss=0.00006, val_loss=0.06870, val_acc_partial=0.9831,  val_acc_exact=0.9831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64109039108c4028b51d53a1f33119f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 38 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 38: train_loss=0.00005, val_loss=0.06712, val_acc_partial=0.9862,  val_acc_exact=0.9862\n",
      "the model with best val_acc (0.9862) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf0815f7df0488da3ac2a1602135313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 39 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 39: train_loss=0.00004, val_loss=0.06672, val_acc_partial=0.9865,  val_acc_exact=0.9865\n",
      "the model with best val_acc (0.9865) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ab950027ae4d9b8c747657159eba72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 40 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 40: train_loss=0.00005, val_loss=0.07902, val_acc_partial=0.9826,  val_acc_exact=0.9826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242356d0056346bdb228aa059a395f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 41 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 41: train_loss=0.00006, val_loss=0.07698, val_acc_partial=0.9804,  val_acc_exact=0.9804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01737a2304b546d19607490a66bbcdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 42 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 42: train_loss=0.00005, val_loss=0.07572, val_acc_partial=0.9849,  val_acc_exact=0.9849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac99caa474e49beade8cb683daa8858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 43 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 43: train_loss=0.00004, val_loss=0.05586, val_acc_partial=0.9841,  val_acc_exact=0.9841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee8d08229904c6198812c3de049a392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 44 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 44: train_loss=0.00004, val_loss=0.08233, val_acc_partial=0.9846,  val_acc_exact=0.9846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ef97af11f8459b814e5e5b531fe56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 45 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 45: train_loss=0.00005, val_loss=0.06796, val_acc_partial=0.9860,  val_acc_exact=0.9860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9555e81c45264be191b321474af2e2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 46 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 46: train_loss=0.00003, val_loss=0.06631, val_acc_partial=0.9858,  val_acc_exact=0.9858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2634cfe4f4b84943a3d5a7c135d89a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 47 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 47: train_loss=0.00004, val_loss=0.08526, val_acc_partial=0.9866,  val_acc_exact=0.9866\n",
      "the model with best val_acc (0.9866) was saved to disk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4984d844074067a80df2665138c4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 48 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 48: train_loss=0.00004, val_loss=0.06453, val_acc_partial=0.9862,  val_acc_exact=0.9862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e05ba007c94fa0bcd75ed22f1902ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 49 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 49: train_loss=0.00210, val_loss=0.06778, val_acc_partial=0.9831,  val_acc_exact=0.9831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fea86a0308b4c3f8928e028bb599a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 50 of 50:   0%|          | 0/422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 50: train_loss=0.00005, val_loss=0.07529, val_acc_partial=0.9849,  val_acc_exact=0.9849\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# model training...\n",
    "##########################\n",
    "\n",
    "DO_TRAIN = True  # false if you want to skip this cell\n",
    "COMMENT = 'test'\n",
    "\n",
    "if DO_TRAIN:\n",
    "    # load dataloader \n",
    "    train_dataloader, val_dataloader = fetch_dataloader(args, args.train_batch_size, train=True, train_val_split='train-val')\n",
    "\n",
    "    # set writer for tensorboard\n",
    "    writer, current_log_path = set_writer(log_path = args.output_dir if args.restore_file is None else os.path.dirname(args.restore_file),\n",
    "                        comment = COMMENT, \n",
    "                        restore = args.restore_file is not None) \n",
    "\n",
    "    args.log_dir = current_log_path\n",
    "\n",
    "    # save used param info to writer and logging directory\n",
    "    writer.add_text('Params', pprint.pformat(args.__dict__))\n",
    "    \n",
    "    with open(os.path.join(args.log_dir, 'params.txt'), 'w') as f:\n",
    "        pprint.pprint(args.__dict__, f, sort_dicts=False)\n",
    "\n",
    "    # start training\n",
    "    print('Start training with args set above...')\n",
    "    train_and_evaluate(model, train_dataloader, val_dataloader, loss_fn, optimizer, writer, args)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries & modules\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "# from ocra import *\n",
    "from loaddata import *\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epoch 50: test_loss=0.07836, test_acc_partial=0.9844, test_acc_exact=0.9844\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# model testing...\n",
    "##########################\n",
    "\n",
    "# testing parameters\n",
    "DO_TEST = True # false if you want to skip this cell\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# give path for the model to load, or None if you want to continue with the current trained model\n",
    "# load_model_path = \"./pretrained/multimnist_cluttered/run1.pt\"\n",
    "load_model_path = None\n",
    "# load_model_path = './results/svrt_task1/Nov27_5848_test/best_model_epoch70_acc0.9899.pt'\n",
    "if DO_TEST:\n",
    "    if load_model_path: \n",
    "        # if path is given, load a saved model (make sure that you loaded right model args)\n",
    "        print(\"param file will be loaded from your saved model folder\")\n",
    "        params_filename = os.path.dirname(load_model_path) + '/params.txt'\n",
    "        assert os.path.isfile(params_filename), \"No param flie exists\"\n",
    "\n",
    "        # remove the arguments that caanot be translated into literal\n",
    "        removelist = ['device'] \n",
    "        args = parse_params_wremove(params_filename, removelist) \n",
    "        args.device = device \n",
    "        \n",
    "        # print params\n",
    "        pprint.pprint(args.__dict__, sort_dicts=False)\n",
    "        \n",
    "        # load model\n",
    "        model = ResNet_model(args).to(args.device) \n",
    "        model.load_state_dict(torch.load(load_model_path,map_location=args.device))\n",
    "        print('model loaded.')\n",
    "        \n",
    "        # get test results\n",
    "        model.eval()\n",
    "        test_dataloader = fetch_dataloader(args, args.test_batch_size, train=False)\n",
    "        test_loss, test_acc_partial, test_acc_exact = test(model, test_dataloader, args)\n",
    "        print(\"==> Epoch %02d: test_loss=%.5f, test_acc_partial=%.4f, test_acc_exact=%.4f\"\n",
    "              % (args.n_epochs, test_loss, test_acc_partial, test_acc_exact))\n",
    "\n",
    "    else: # use the current trained model to get results\n",
    "        model.eval()\n",
    "        test_dataloader = fetch_dataloader(args, args.test_batch_size, train=False)\n",
    "        test_loss, test_acc_partial, test_acc_exact = test(model, test_dataloader, args)\n",
    "        print(\"==> Epoch %02d: test_loss=%.5f, test_acc_partial=%.4f, test_acc_exact=%.4f\"\n",
    "              % (args.n_epochs, test_loss, test_acc_partial, test_acc_exact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
